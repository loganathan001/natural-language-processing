{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On branch master\r\n",
      "Your branch is up to date with 'origin/master'.\r\n",
      "\r\n",
      "Changes not staged for commit:\r\n",
      "  (use \"git add <file>...\" to update what will be committed)\r\n",
      "  (use \"git checkout -- <file>...\" to discard changes in working directory)\r\n",
      "\r\n",
      "\t\u001b[31mmodified:   ../Setup.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   sample.ipynb\u001b[m\r\n",
      "\t\u001b[31mmodified:   utils.py\u001b[m\r\n",
      "\r\n",
      "Untracked files:\r\n",
      "  (use \"git add <file>...\" to include in what will be committed)\r\n",
      "\r\n",
      "\t\u001b[31m../Starspace/\u001b[m\r\n",
      "\t\u001b[31m../boost_1_63_0.zip\u001b[m\r\n",
      "\t\u001b[31m../boost_1_63_0.zip.1\u001b[m\r\n",
      "\t\u001b[31m../boost_1_63_0.zip.2\u001b[m\r\n",
      "\t\u001b[31m../boost_1_63_0.zip.3\u001b[m\r\n",
      "\t\u001b[31m../boost_1_63_0.zip.4\u001b[m\r\n",
      "\t\u001b[31m../boost_1_63_0.zip.5\u001b[m\r\n",
      "\t\u001b[31m../boost_1_63_0.zip.6\u001b[m\r\n",
      "\t\u001b[31m../boost_1_63_0.zip.7\u001b[m\r\n",
      "\t\u001b[31m../boost_1_63_0/\u001b[m\r\n",
      "\t\u001b[31m../dialogue_manager.py\u001b[m\r\n",
      "\t\u001b[31m../main_bot.py\u001b[m\r\n",
      "\t\u001b[31mdb.sqlite3\u001b[m\r\n",
      "\t\u001b[31mintent_recognizer.pkl\u001b[m\r\n",
      "\t\u001b[31mstarspace_embedding.tsv\u001b[m\r\n",
      "\t\u001b[31mtag_classifier.pkl\u001b[m\r\n",
      "\t\u001b[31mtfidf_vectorizer.pkl\u001b[m\r\n",
      "\t\u001b[31mthread_embeddings_by_tags.zip\u001b[m\r\n",
      "\t\u001b[31mthread_embeddings_by_tags/\u001b[m\r\n",
      "\t\u001b[31m../util.py\u001b[m\r\n",
      "\t\u001b[31m../utils.py\u001b[m\r\n",
      "\t\u001b[31m../week3/?\u001b[m\r\n",
      "\t\u001b[31m../week3/GoogleNews-vectors-negative300.bin\u001b[m\r\n",
      "\t\u001b[31m../week3/GoogleNews-vectors-negative300.bin.gz\u001b[m\r\n",
      "\t\u001b[31m\"../week3/S\\275\"\u001b[m\r\n",
      "\t\u001b[31m../week3/boost_1_63_0.zip\u001b[m\r\n",
      "\t\u001b[31m../week3/boost_1_63_0/\u001b[m\r\n",
      "\t\u001b[31m../week3/common/\u001b[m\r\n",
      "\t\u001b[31m\"../week3/d\\276\"\u001b[m\r\n",
      "\t\u001b[31m../week3/rts \u001b[m\r\n",
      "\t\u001b[31m\"../week3/\\201\\276\"\u001b[m\r\n",
      "\t\u001b[31m../week4/week4_seq2seq-solution-peer-review-1.ipynb\u001b[m\r\n",
      "\t\u001b[31m../week4/week4_seq2seq-solution-peer-review-2.ipynb\u001b[m\r\n",
      "\t\u001b[31m../week4/week4_seq2seq-solution-peer-review-3.ipynb\u001b[m\r\n",
      "\t\u001b[31m../week4/week4_seq2seq-solution-peer-review-4.ipynb\u001b[m\r\n",
      "\t\u001b[31m../week4/week4_seq2seq-solution-peer-review-5.ipynb\u001b[m\r\n",
      "\r\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\r\n"
     ]
    }
   ],
   "source": [
    "!git add  sample.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  thread_embeddings_by_tags.zip\n",
      "   creating: thread_embeddings_by_tags/\n",
      "  inflating: thread_embeddings_by_tags/python.pkl  \n",
      "  inflating: thread_embeddings_by_tags/java.pkl  \n",
      "  inflating: thread_embeddings_by_tags/c#.pkl  \n",
      "  inflating: thread_embeddings_by_tags/javascript.pkl  \n",
      "  inflating: thread_embeddings_by_tags/php.pkl  \n",
      "  inflating: thread_embeddings_by_tags/c_cpp.pkl  \n",
      "  inflating: thread_embeddings_by_tags/swift.pkl  \n",
      "  inflating: thread_embeddings_by_tags/vb.pkl  \n",
      "  inflating: thread_embeddings_by_tags/ruby.pkl  \n",
      "  inflating: thread_embeddings_by_tags/r.pkl  \n"
     ]
    }
   ],
   "source": [
    "!unzip thread_embeddings_by_tags.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (dialogue_manager.py, line 26)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/home/loganathan001/tfve/tfve/lib/python3.6/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3326\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-681452c9411a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from dialogue_manager import DialogueManager\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/home/loganathan001/dev/git/natural-language-processing/project/dialogue_manager.py\"\u001b[0;36m, line \u001b[0;32m26\u001b[0m\n\u001b[0;31m    question_vec = #### YOUR CODE HERE ####\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from dialogue_manager import DialogueManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 3.4MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /home/loganathan001/tfve/tfve/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/loganathan001/tfve/tfve/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.17.2)\n",
      "Collecting joblib>=0.11 (from scikit-learn->sklearn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/c1/50a758e8247561e58cb87305b1e90b171b8c767b15b12a1734001f41d356/joblib-0.13.2-py2.py3-none-any.whl (278kB)\n",
      "\u001b[K     |████████████████████████████████| 286kB 33.6MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=72c099b4dd6f5627603c4e42ae6ee4ced0c4efeae2eb8e3aff13374c78f5aa6e\n",
      "  Stored in directory: /home/loganathan001/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.13.2 scikit-learn-0.21.3 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "word_embeddings, embeddings_dim = load_embeddings('starspace_embedding.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_ids, thread_embeddings = unpickle_file('thread_embeddings_by_tags/java.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Difference between checked and unchecked exceptions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vec = question_to_vec(question, word_embeddings, embeddings_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383456, 100)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264482\n"
     ]
    }
   ],
   "source": [
    "max_cosine_value = -1.0\n",
    "max_question_id = -1;\n",
    "for i, thread_vec in enumerate(thread_embeddings) :\n",
    "    cosine_value = cosine_similarity([question_vec], [thread_vec])[0]\n",
    "    if cosine_value > max_cosine_value:\n",
    "        max_cosine_value = cosine_value\n",
    "        max_question_id = i\n",
    "        \n",
    "print(max_question_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264482"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_matching_thread_index(question_vec,thread_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([264482])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "pairwise_distances_argmin(np.array([question_vec]),thread_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264482\n"
     ]
    }
   ],
   "source": [
    "cs = np.apply_along_axis(\n",
    "    lambda x: cosine_similarity([question_vec], [x])[0], \n",
    "    1, \n",
    "     thread_embeddings\n",
    "                   )\n",
    "max_index = np.argmax(cs, axis=0)[0]\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(383456, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-27fea07409f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion_vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mthread_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_jupyter_gym/tf_jupyter_gym/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[0;32m-> 1036\u001b[0;31m                         dense_output=dense_output)\n\u001b[0m\u001b[1;32m   1037\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf_jupyter_gym/tf_jupyter_gym/lib/python3.6/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cs = cosine_similarity([question_vec]*thread_embeddings.shape[0], thread_embeddings)[0]\n",
    "max_index = np.argmax(cs, axis=0)[0]\n",
    "print(max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.apply_along_axis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/loganathan001/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INTENT_RECOGNIZER': 'intent_recognizer.pkl',\n",
       " 'TAG_CLASSIFIER': 'tag_classifier.pkl',\n",
       " 'TFIDF_VECTORIZER': 'tfidf_vectorizer.pkl',\n",
       " 'THREAD_EMBEDDINGS_FOLDER': 'thread_embeddings_by_tags',\n",
       " 'WORD_EMBEDDINGS': 'starspace_embedding.tsv'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESOURCE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2158"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread_ids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ai.yml Training: [####################] 100%\n",
      "botprofile.yml Training: [####################] 100%\n",
      "computers.yml Training: [####################] 100%\n",
      "conversations.yml Training: [####################] 100%\n",
      "drugs.yml Training: [####################] 100%\n",
      "emotion.yml Training: [####################] 100%\n",
      "food.yml Training: [####################] 100%\n",
      "gossip.yml Training: [####################] 100%\n",
      "greetings.yml Training: [####################] 100%\n",
      "history.yml Training: [####################] 100%\n",
      "humor.yml Training: [####################] 100%\n",
      "literature.yml Training: [####################] 100%\n",
      "money.yml Training: [####################] 100%\n",
      "movies.yml Training: [####################] 100%\n",
      "politics.yml Training: [####################] 100%\n",
      "psychology.yml Training: [####################] 100%\n",
      "science.yml Training: [####################] 100%\n",
      "sports.yml Training: [####################] 100%\n",
      "trivia.yml Training: [####################] 100%\n"
     ]
    }
   ],
   "source": [
    "from chatterbot import ChatBot\n",
    "from chatterbot.trainers import ChatterBotCorpusTrainer\n",
    "\n",
    "chatbot = ChatBot('Ron Obvious')\n",
    "\n",
    "# Create a new trainer for the chatbot\n",
    "trainer = ChatterBotCorpusTrainer(chatbot.storage)\n",
    "\n",
    "# Train the chatbot based on the english corpus\n",
    "trainer.train(\"chatterbot.corpus.english\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Statement text:Artificial Intelligence is the branch of engineering and science devoted to constructing machines that think.>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a response to an input statement\n",
    "chatbot.get_response(\"is it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_recognizer = unpickle_file('intent_recognizer.pkl')\n",
    "tfidf_vectorizer = unpickle_file('tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stackoverflow'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = 'What are generics'\n",
    "prepared_question = text_prepare(question)\n",
    "features = tfidf_vectorizer.transform([prepared_question])\n",
    "intent = intent_recognizer.predict(features)\n",
    "intent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_classifier = unpickle_file('tag_classifier.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'java'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_classifier.predict(features)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
